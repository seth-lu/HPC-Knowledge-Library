# 高性能零内存开销直接卷积

## 摘要

深度神经网络中卷积层的计算通常需要额外的内存(用于打包目的或作为算法的一部分)来交换空间以提高性能。这种方法的问题有两个方面，额外的内存开销让程序无法运行在内存有限的设备（通常是嵌入式设备）。而且没有针对执行卷积进行优化意味着获得的性能通常低于常规预期。这篇文章证明，如果正确实现，直接卷积可以消除所有内存开销，获得比传统和嵌入式CPU架构上卷积层的现有高性能实现更好的性能，而且高性能的直接卷积表现出更好的扩展性能，当增加线程数量时性能下降更少。

## 介绍

现在的计算卷积层的方法通常需要打包（重塑和有选择地复制原始输入数据的部分），因为神经网路基于在基本线性代数子程序(BLAS)等计算库中设立的高度优化的例程(例如矩阵-矩阵乘法)，因此需要额外的内存空间。会有以下问题：

- 重塑和复制输入数据元素的额外工作是一种带宽有限的操作，会对整体系统性能造成额外的、重要的时间损失。

- 卷积层产生的矩阵通常具有与传统高性能计算(HPC)应用产生的矩阵不同的维度，与HPC矩阵相比，矩阵-矩阵乘法例程通常不能在卷积矩阵上实现良好的性能。

这篇文章在这里举了一个例子，使用AMD Piledriver架构（4核）在AlexNet的各种卷积层的性能。得出结论用OpenBLAS+ Packing的性能不到矩阵乘法本身性能的80%，打包让整体性能降低了20%以上。而这篇文章中的直接卷积的性能超过了OpenBLAS+ Packing（即使不考虑打包的花费）。

现在是时候重新审视卷积层是如何计算的了。基于深度神经网络的机器学习任务越来越多地被放置在计算能力和内存容量方面受到限制的边缘设备上，现有的以内存容量换取性能的方法对这些设备来说不再是可行的解决方案。提高性能和减少内存开销也带来更好的能源效率。现在很多工作通过近似、量化或权重的稀疏化来减少卷积层的内存占用，很少有工作解决为了使用高性能例程所需的额外内存需求。

## 贡献

这篇文章的贡献如下:

- 高性能直接卷积。证明了直接卷积的高性能，在实际性能、并行性和减少内存开销方面优于基于矩阵-矩阵乘法实现的卷积。证明了直接卷积是一种计算卷积层的可行方法。

- 输入/输出特征图和核权值的数据布局。提出了新的数据布局，用于存储使用直接卷积算法计算卷积层所需的输入、输出和核权重。这些新数据布局所需的空间与用于存储输入、输出和内核权重的现有数据存储方案相同，而不是用任何打包或复制。

## 非直接卷积的低效的地方

突出了许多深度学习框架中使用的现有方法计算卷积的低效的地方。

### 基于傅立叶变换的快速实现

基于快速傅里叶变换(FFT)用于减少计算卷积时执行的浮点运算次数。

但需要将内核权重填充到输入图像的大小，这需要占用大量内存。

将图像细分为更小的块或块的替代方法(Dukhan)已经被提出了。即使使用这种方法，还是需要对内核进行额外的填充，导致内存需求增加7到28倍，而且实时分割会导致显著的性能开销。

### 基于矩阵乘法的实现

将输入(图像和核权重)转换为矩阵，并利用基本线性代数子程序(BLAS)中的高性能矩阵-矩阵乘法例程进行计算。有以下低效的地方：

- 需要额外的内存。将图像转换为矩阵，降低了纬度，通常用im2col的操作来实现，该操作将$W_i×H_i×C_i$图像复制到$(H_f×W_f×C_i)×(H_o×W_o)$矩阵中，然后将该矩阵用作矩阵乘法调用的输入。计算中会重复用到部分元素，这些元素会被复制，占用额外内存。

  Cho和Brand提出了一种降低机制，通过减少包装过程中所需的重复量来提高内存效率。在其降低例程中，内存占用比im2col平均减少了3.2倍。这是通过以额外的矩阵-矩阵乘法调用为代价消除所需的复制量来实现的。尽管如此，这仍然是额外的内存需求，并且它们的计算仍然依赖于矩阵-矩阵乘法，对于卷积产生的矩阵来说，这种乘法通常不是最优的。

- 通常性能达不到最佳。在大多数BLAS库中，矩阵-矩阵乘法不是为了卷积设计的。当输入矩阵的内部维数(即两个输入矩阵之间共有的维数)小于输出矩阵的整体维数时，矩阵-矩阵乘法例程的性能最佳。这种特殊的矩阵形状通常出现在科学和工程代码中，这些库就是针对这些进行优化的。im2col将输入重塑为$(H_f ×W_f ×C_i)×(H_o ×W_o)$矩阵。这意味着输入矩阵的内部维度通常是两个维度中较大的一个。因此，在这组特定的输入形状上，矩阵-矩阵乘法的性能通常明显低于可实现的最佳性能。

  现有BLAS库通过划分输入矩阵的行和列来获得并行性。这使矩阵形状偏离矩阵-矩阵乘法例程所期望的形状更远。因此，随着线程数量的增加，例程的效率会受到影响。

## 高性能直接卷积

直接卷积的简单实现本质上是围绕计算单个输出元素的乘法和累加计算语句的六个完美嵌套循环。循环顺序的任何排列都将产生正确的结果。然而，为了获得直接卷积的高性能实现，必须将这些循环及其顺序适当地映射到给定的体系结构。

### 将循环映射到体系结构的策略

1. 介绍高性能矩阵-矩阵乘法所使用的模型架构
2. 识别有效利用可用计算单元的循环。
3. 确定外部循环的顺序，以提高数据重用

#### 模型架构

假设模型体系结构具有以下特征:

- **矢量寄存器。**假设模型架构使用单指令多数据(SIMD)指令集。一组指令对多组数据通进行并行操作。
- **FMA指令。**乘积累加指令，计算两个数字的乘积并将其添加到一个累加器中，可以减少指令数目和时钟周期，加速运算。
- **加载/存储架构。**假设该体系结构是加载/存储体系结构，在对加载的数据执行操作之前，必须将数据加载到寄存器中。在指令直接从内存进行计算的体系结构上，我们假设不使用这些指令。

#### 循环来饱和计算

当所有$N_{fma}$单元每个周期计算一个FMA时，可以获得最大性能。然而，由于每个FMA指令具有$L_{fma}$周期的延迟，这意味着必须至少有$L_{fma}$独立的FMA指令发出到每个计算单元，每条FMA指令都可以计算$N_{vec}$输出元素（？不懂FMA指令）。所以，每个周期中计算的独立输出元素的最小数量大于等于单元数乘周期数乘每条FMA指令可以计算的输出元素。

由于最小数量必须是$N_{vec}$的倍数，即2的幂次幂，输出有三个维度$(H_o × W_o × C_o)$，其中$H_o$和$W_o$主要是输入大小的函数，而$C_o$是卷积层的设计参数。并且$C_o$可以选择(并且在实践中也是如此)为2的幂次幂，因此$j$循环被选为最内部的循环。

由于最小数量E高度依赖于FMA计算单元的数量和能力，我们希望确保有足够的输出元素来完全饱和计算。因此，选择遍历输出图像同一行中的元素的$k$循环作为$j$循环周围的循环。（选$W_o$/$H_o$是任意的，分析过程相同）

#### 循环以优化数据重用

随后的循环是为了尽可能高效地将数据传递给计算单元。

内部的两个循环($j$和$k$)遍历多个输出元素，以确保可以执行足够的独立FMA操作，以避免计算单元停滞。由于模型体系结构是加载/存储体系结构，这意味着这些输出元素已经在寄存器中。因此，希望引入的数据是用于接下来在输出元素中进行乘积累加的数据。

为了计算单个输出元素，卷积核$H_f × W_f × C_i$都与输入图像中的适当元素相乘，并累积到输出元素中。这意味着从最内层到最外层顺序的下三个循环是$i,m,n$循环。这种循环的顺序是基于大多数卷积层的输入是另一个卷积层的输出的观察来确定的。这意味着以相同的顺序访问输入和输出中的数据是可取的。因此，我们希望在行($n$)之前访问通道($i$)中的输入元素，这给了我们$i,n,m$顺序的循环。

在确定了最初的六个循环中的五个之后，这意味着最外层的循环是循环遍历剩下的输出的不同行。原循环顺序 算法1 $(i,j,k,l,m,n)$变换为$(l,n,m,i,k,j)$循环排序。

------

算法1朴素卷积算法

Input: Input I, Kernel Weights F, stride s;
Output: Output O
for i = 1 to $C_i$ do
     for j = 1 to $C_o$ do
          for k = 1 to $W_o$ do
               for l = 1 to $H_o$ do
                   for m = 1 to $W_f$ do
                        for n = 1 to $H_f$ do
                             $ O_{j,k,l} += I_{i,k×s+m,l×s+n} × F_{i,j,m,n}$

------

算法2重排序卷积算法

Input: Input I, Kernel Weights F, stride s;
Output: Output O
for l = 1 to $H_o$ do
     for n = 1 to $H_f$ do
          for m = 1 to $W_f$ do
               for i = 1 to $C_i$ do
                   for k = 1 to $W_o$ do
                        for j = 1 to $C_o$ do
                            $ O_{j,k,l} += I_{i,k×s+m,l×s+n} × F_{i,j,m,n}$

------

#### 阻塞内存层次结构

维持峰值性能所需的最小输出元素的上限是逻辑寄存器数量乘每条FMA指令可以计算的输出元素。可用寄存器数量的上限意味着最多只能在寄存器中保留$N_{reg}N_{vec}$个元素。

寄存器数量有限，没法把所有元素都放入寄存器，为了减少数据频繁换入换出造成的性能减低需要对最内的两层循环分块（分成$C_{o,b}$和$W_{o,b}$大小的循环阻塞/平铺）。（选择$C_{o,b}$为向量长度$N_{vec}$的倍数，以便更好地利用SIMD指令进行计算）

将循环阻塞应用于原始$j$和$k$循环，将每个输出通道的一行分解为更小的输出图像，每个输出图像的行宽和输出通道分别为$W_{o,b}$和$C_{o,b}$。由于循环阻塞将整个卷积分解成更小的卷积，因此前面描述的循环排序仍然适用。

循环$j'$和$k'$分别遍历输出的通道维度和行维度中的块。此外，循环$jj$和$kk$对各自的通道和行块进行迭代。观察到访问同一行中的输入元素需要访问同一行中的核权值。这表明循环的顺序应该类似于遍历内核权重的循环。因此，$k'$循环嵌套在$l$和$n$循环之间。$j'$循环被设置为最外层的循环，因为它是一个促进并行化的并行循环。

可以进一步将输入数据集划分为更小的分区，以便它们适合适当的缓存级别。$jj$和$kk$周围的循环将$H_f ×W_f ×C_i$中间结果累积到存储在寄存器中的输出中。由于$H_f$和$W_f$，即内核权重的大小，通常小于$C_i$，因此我们选择划分$i$循环，该循环在$C_i$输入通道上迭代，用于内存层次结构中的下一层。

------

算法3并行化直接卷积算法

Input: Input I, Kernel Weights F, stride s;<br>Output: Output O<br>for $j'$ = 1 to $C_o/C_{o,b}$ in Parallel do<br>
       for $i'$ = 1 to $C_i/C_{i,b}$ in Parallel do<br>            for l = 1 to $H_o$ do<br>
               for $k'$ = 1 to $W_o/W_{o,b}$  do <br>                  for n = 1 to $H_f$ do<br>                     for m = 1 to $W_f$ do<br>
                         for ii = 1 to $C_{i,b}$ do<br>
                              for kk = 1 to $W_{o,b}$ do<br>
                                  for jj = 1 to $C_{o,b}$ do<br>
 $ O_{j'C_{o,b}+jj,k'W_{o,b}+kk,l} += I_{i'C_{i,b}+ii,sk'W{o,b}+kk+m,l,s+n} × F_{i'C_{i,b}+ii,j'×C_{o,b}+jj,m,n}$

------

### 并行性

所有输出元素都可以并行计算。由于输出是一个三维对象$(H_o × W_o × C_o)$，这意味着可以在至少三个不同的维度中提取并行性。

直接卷积实现在输出通道($C_o$)维中提取并行性。每个线程被分配一个输出元素块来计算，其中每个输出元素块的大小为$H_o × W_o × C_o/p$，其中$p$为所使用的线程数

## 卷积友好的数据布局

输入和内核数据提出了新的数据布局，以便尽可能多地以单位步进访问数据。这改善了数据访问，并避免了从内存层次结构的较低级别访问数据时代价高昂的停顿。修改布局的一个关键标准是输出和输入图像应该具有相同的数据布局。这是因为大多数卷积层的输入是另一个卷积层的输出。将它们保持在相同的数据布局将避免昂贵的卷积层之间的数据重塑。然而，为了确保与原始输入图像的兼容性，没有将所提出的布局强加于第一个卷积层的输入。

### 输入/输出布局

希望以单位步长访问输出数据。因此，我们通过考虑如何使用算法3中所示的循环顺序访问元素来确定输出数据布局。在内部循环中访问的数据应该比在外部循环中访问的数据更靠近内存。

五层循环($j,k,l,kk,jj$)遍历输出数据，这建议使用五维数据布局。然而，如果我们要将它用于输入数据，这是次优的。这是因为需要输入行中的$W_f$个元素来计算一个输出元素。在五维布局中，一行输入被分割成$W_{o,b}$个元素块。这意味着需要来自两个独立的$W_{o,b}$块的输入元素的输出元素将产生很大的损失，因为这些输入元素在内存中相隔很远。因此，我们不按照kk循环来布局数据。

建议的输入/输出布局，输出数据被组织成$H_o × W_o × C_{o,b}$的连续块，其中在每个块中，元素首先在通道维度中布局，然后被组织成长度为$C_{o,b}$的$H_o × W_o$行主序矩阵。

内核布局中最快的维度是阻塞的输出通道($C_{o,b}$)维度，它由最内层的循环决定。其余维度从快到慢依次是阻塞的输入通道($C_{i,b}$)，其次是内核的列($W_f$)和行($H_f$)，然后是输入通道($C_i/C_{i,b}$)，最后是输出通道($C_o/C_{o,b}$)。

### 向后兼容性

鉴于卷积神经网络(CNN)在该领域的成功部署，所提出的数据布局的变化将意味着训练后的网络无法直接受益于所提出的直接卷积实现。然而，为了让一个经过训练的网络使用提出的算法，只需要将核权重重新排列到所提出的数据布局中，这是一次性的成本。其他网络层，如跳过层和激活层是逐点操作，不需要在实现中进行任何重大更改。尽管如此，重新排序用于计算这些层的循环可能会产生更好的性能。

## 结果/结论

直接卷积实现在所有架构上比所有基于sggem的卷积至少高出10%，最高可达400%。对于只针对HPC矩阵进行优化的BLAS库(OpenBLAS)，看到在4个线程上至少有1.5倍的性能提升。

直接卷积目前（这篇文章发表与18年）达到了Intel、AMD和ARM架构理论峰值的87.5%、58.2%和88.9%，而在HPC矩阵上的SGEMM达到了相同架构的89%、54%和92%的峰值。

这篇文章在cpu上实现了直接卷积算法，未在GPU上验证。

# 读后感

这篇文章争对的是卷积运算时的内存问题，文章指出常用的卷积计算方式内存使用十分巨大，在一些算力和内存受限的场景并不适合，而且除开用内存换性能，还有打包会需要额外内存和性能损失。文章介绍了常用的两个卷积算法，指出了它们低效的地方。一个是傅里叶变换（FFT）算法，具体怎么做不知道，但知道要用傅里叶变换算法需要将卷积核填充至和图像一样大小，通常卷积核比图像小很多，用这个会产生比必要的内存多得多，填充也会产生额外的开销，即使有将图像细分为更小的块的方式内存占用还是巨大，还多出来将原始图像转换为FFT能用的矩阵的开销。另一种是基于im2col的矩阵-矩阵乘法，需要先通过im2col变换重塑矩阵，首先这是一笔开销，转换会复制计算中会重复用到的部分元素，转换后的矩阵占用的内存远比初始图像高，并且因为输入张量和卷积核的大小通常差距很大，导致转换后的矩阵形状比较特殊通常不是这个算法能达到性能最佳的形状。而且大部分高性能计算库是争对其他科学和工程优化的，没有争对卷积优化。这些导致卷积运算使用该方法性能达不到理论最佳的性能。

这篇文章认为在内存受限的场景应该使用直接卷积算法。直接卷积算法没有额外的内存开销，然后这篇文章对直接卷积算法进行了优化，使得直接卷积算法的性能不输常用的卷积算法。这篇文章只在CPU实现了，有些优化也是争对CPU。首先这篇文章针对循环的顺序进行了优化，因为使用了FMA指令（乘积累加指令）每条FMA指令的可以计算的输出原始是2的幂次，所以选择可以主动控制为2的幂次的卷积层的设计参数为最内层循环，然后为了饱和运算选择遍历输出图像同一行中的元素（同一列也行，只要是输出图像的就行）。为了计算输出元素需要所有的卷积核数据，并且历遍卷积核和历遍输出元素顺序一致可以减少换入换出，这样5层循环就决定了，剩下一层循环就放在最外层。（为啥总共是6层而不是卢师兄论文中提到的7层循环，是因为这篇论文讨论的是单张输入图片，少了卢师兄论文中批次那层，这篇的论文最外层加一层历遍所有图片就是7层循环）。

然后因为寄存器/缓存数量有限，对循环做了阻塞，将循环分块，减少数据在寄存器和内存之间换入换出的开销，提升数据复用性，提升了性能。数据布局也针对这个算法进行了设计，数据被组织成$H_o × W_o × C_{o,b}$的连续块。

最后这篇论文得出了直接卷积算法是可行的，内存开销远小于矩阵乘法实现的卷积运算，性能上也优于达不到最佳性能的矩阵乘法。但它只是在CPU上实现了，不知道在GPU上表现如何。

