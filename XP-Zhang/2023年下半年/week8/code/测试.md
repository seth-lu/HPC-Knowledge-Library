尝试在directConvolution_tensor使用和 C = A.convolutionWithStride(B,strides[i]);一样的数据结构size_t，还是慢5倍（测试结果为和size_t/int64_t无关，也和{}无关）
尝试使用Tensor1D和Tensor4D而不是Tensor
template<typename T>
void directConvolution_tensor4d(const Tensor4D<T>& A,const Tensor4D<T>& B,Tensor4D<T>& C,int64_t s){
    for (int64_t i = 0; i < C.num_batch(); ++i){
        for (int64_t j = 0; j < C.num_channel(); ++j){
			for (int64_t m = 0; m < C.num_height(); ++m){
                for (int64_t n = 0; n < C.num_width(); ++n){
                    // for (int64_t r = 0; r < A.num_channel(); ++r){
                    for (int64_t r = 0; r < B.num_channel(); ++r){
                        for (int64_t u = 0; u < B.num_height(); ++u){
                            for (int64_t v = 0; v < B.num_width(); ++v) {
								// C(i, j, m, n) += A(i, r, m + u, n + v) * B(j, r, u, v);
                                C(i, j, m, n) += A(i, r, m * s + u, n * s + v) * B(j, r, u, v);
								//C.setTensors(i, j, m, n, (A(i, r, m + u, n + v) * B(j, r, u, v)));
							}
                        }
                    }
                }
            }
		}
    }
}
结果，快了一点，见times_t1_O2.png
然后把T改成double
void directConvolution_tensor1d(const Tensor1D<double>& A,const Tensor1D<double>& B,Tensor1D<double>& C,int64_t s){
    for (int64_t i = 0; i < C.num_batch(); ++i){
        for (int64_t j = 0; j < C.num_channel(); ++j){
			for (int64_t m = 0; m < C.num_height(); ++m){
                for (int64_t n = 0; n < C.num_width(); ++n){
                    // for (int64_t r = 0; r < A.num_channel(); ++r){
                    for (int64_t r = 0; r < B.num_channel(); ++r){
                        for (int64_t u = 0; u < B.num_height(); ++u){
                            for (int64_t v = 0; v < B.num_width(); ++v) {
								// C(i, j, m, n) += A(i, r, m + u, n + v) * B(j, r, u, v);
                                C(i, j, m, n) += A(i, r, m * s + u, n * s + v) * B(j, r, u, v);
								//C.setTensors(i, j, m, n, (A(i, r, m + u, n + v) * B(j, r, u, v)));
							}
                        }
                    }
                }
            }
		}
    }
}
结果见times_t2_O2.png
改成内部申请空间
Tensor1D<double> directConvolution_tensor1d_t(const Tensor1D<double>& A,const Tensor1D<double>& B,int64_t s){
    Tensor1D<double> C(A.num_batch(),B.num_batch(), (A.num_height() - B.num_height()) / s + 1, (A.num_width() - B.num_width()) / s + 1);

    for (int64_t i = 0; i < C.num_batch(); ++i){
        for (int64_t j = 0; j < C.num_channel(); ++j){
			for (int64_t m = 0; m < C.num_height(); ++m){
                for (int64_t n = 0; n < C.num_width(); ++n){
                    // for (int64_t r = 0; r < A.num_channel(); ++r){
                    for (int64_t r = 0; r < B.num_channel(); ++r){
                        for (int64_t u = 0; u < B.num_height(); ++u){
                            for (int64_t v = 0; v < B.num_width(); ++v) {
								// C(i, j, m, n) += A(i, r, m + u, n + v) * B(j, r, u, v);
                                C(i, j, m, n) += A(i, r, m * s + u, n * s + v) * B(j, r, u, v);
								//C.setTensors(i, j, m, n, (A(i, r, m + u, n + v) * B(j, r, u, v)));
							}
                        }
                    }
                }
            }
		}
    }

    return C;
}
结果见times_t3_O2.png
然后把tensor4d的直接卷积改成
	void convolutionWithStride_t (const Tensor4D<T>& B, Tensor4D<T>& C, int64_t s) {
		for(size_t i = 0; i < C.batch; ++i)
			for(size_t j = 0; j < C.channel; ++j)
				for(size_t m = 0; m < C.height; ++m)
					for(size_t n = 0; n < C.width; ++n)
						for(size_t r = 0; r < B.channel; ++r)
							for(size_t u = 0; u < B.height; ++u)
								for(size_t v = 0; v < B.width; ++v)
									C(i, j, m, n) += (*this)(i, r, m * s + u, n * s + v) * B(j, r, u, v);
		
	}
结果见times_t4_O2.png

测试不同的优化选项带来的不同效果
-fgcse-after-reload #Perform global common subexpression elimination after register allocation has finished. 在寄存器分配完成后执行全局公共子表达式消除。
见图片
-fipa-cp-clone # Perform cloning to make Interprocedural constant propagation stronger.执行克隆以使程序间常量传播更强。
见图片，效果明显
-floop-interchange #Enable loop interchange on trees.启用树上的环路交换。
见图片

