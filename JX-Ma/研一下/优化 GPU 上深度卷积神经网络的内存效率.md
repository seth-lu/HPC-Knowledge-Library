优化 GPU 上深度卷积神经网络的内存效率

现在的研究主要关注CNN的计算效率，而CNN 的内存效率却在很大程度上被忽视了。

由于CNN的数据结构复杂，内存会对性能产生重大影响。这篇文章研究了不同CNN层的内存效率，讨论了数据布局和内存访问模式对性能的影响。展示实验结果。

摘要 背景-> 本文研究目的 ->实验结果。

导言：介绍CNN,CNN取得成功的原因1. 大规模训练数据集;2.大型的深度神经网络。

介绍几个基于GPU加速的CNN库，如Caffe,Nvidia的CUDNN, 这些库的缺点就是只关注了卷积层的计算效率，而忽视了卷积层中的内存效率。（引出本篇文章的主要工作，关注卷积层中的内存效率）

比较两个常用CNN库的效率，一个是cuda-convnet2(CHWN),一个是cudnnv4(NCHW)布局，

NCHW在CV1上的性能没有CHWN上的性能好，其他层都比它好。

CV1 Input (128x1x28x28) filter(16x1x5x5)

CV2 input(128x16x14x14) filter(16x16x5x5)

CV3 input(128x3x24x24) filter(64x3x5x5)

CV4 input(128x64x12x12) filter(64x64x5x5)

CV5 input(64x3x224x224) filter(96x3x3x3)

在CV1上的$C_i$为1

本文主要研究

1.描述了各种CNN层中的数据布局的特征，并揭示了不同布局对性能的影响。

2. 我们通过提出 GPU 上的快速多维数据布局转换，支持一个网络的多种数据布局。
3. 研究了有内存约束的池化层和软最大层的内存行为，并优化了它们在 GPU 上的内存访问效率。
4. 我们对不同类型的层和有代表性的网络进行了严格的评估和结果分析，并证明了这两种网络的性能
   都有很大提高。

---

背景介绍

1. 介绍了深度学习网络中各层的概念，例如卷积层，池化层，全连接层
2. 介绍了一些CNN库（cuda-convnet)选用的CHWN，使用的是直接卷积。

---

方法

1. 介绍了一些benchmark 深度学习常用的数据集是MNIST NCHW布局，这种布局实现卷积有两种，一种是使用矩阵乘法，另一种基于FFT(快速傅里叶变换)。

MINIST数据集：MNIST 数据集用于手写字符识别。它的训练集包含 50,000 张手写数字图像，测试
数据集包含 10,000 个例子，LeNet [17] 是研究 MNIST 最好的网络。

CIFAR10: 包含 10 个不同类别的物体，如猫、卡车、飞机等，每个类别有 5000 张训练图像和 1000 张
测试图像。

2. 介绍实验环境

---

内存问题：数据布局

1. 卷积层中的数据布局

N通常为16的倍数，不同卷积层宽度和高度有很大的差别，一般输入张量的通道维度为1，或者3,1为灰色图片，3为彩色图片，一般第一层的输出张量作为第二层的输入，所以除了第一次其它层的输入张量的通道通常为16的倍数。==这篇文章的建议是将W和H合并，然后将N作为最低维度==，因此出来了两种候选数据布局，CHWN,HWCN.

cuda-convnet采用的是CHWN, 有些CHWN的性能和NHWC相同，因为没有改变N的内存聚集特征，并且二维卷积操作一般都作用于HW。后面介绍了cuda-convnet（CHWN)和cudnn(NCHW) 的性能比较，结果表明CHWN性能好的CONV层中的==C很小，通常为3或者1==. 其他NCHW较好层的N为32/64。

根据N和C变化得出实验结果

1. N>64, CHWN的效果要比NCHW的好，并且NCHW随着N的变化，性能影响没有很明显，而CHWN随着N变化性能就很明显。本文给出的解释是在GPU上分了32个线程，每个线程处理4个图像，如果N总量少于128，每个线程处理的图像数量就小于4，这样数据重用率就会降低。
2. 当C<32,CHWN效果好，NCHW的性能随着C的变化性能影响很明显，本文解释C>32,NCHW的矩阵拓展会带来更好的数据重用和更高的数据并行。归功于维度合并。
3. 总结起来就是对于N放里面的布局而言，它受N的影响非常明显，对于NCHW受C的影响明显，当N>NX,& C<CX的话CHWN是很好的选择。其他则选择NCHW.



2. 基于FFT实现的数据布局

介绍了不同布局在FFT上面的应用，大概看了一下。这里提到了对于卷积核来说实现FFT需要填充对于卷积核中宽x高为3x3的卷积核，填充浪费很多空间。我们在直接卷积上和im2win上为了使用simd也使用了填充，性能非常差，因为有很多无效的运算，在im2win上面卷积核为3x3的话每计算16个元素有7个元素计算是无效，直接卷积就更多了8次运算中5次无效，他这里解决的办法是使用FFT平铺，我们解决的办法是按照通道平铺，如果全部按照通道平铺的话就是第三种数据布局NHWC.

3. 用于基于CNN的快速数据布局变换

介绍了一种在GPU上实现的CHWN到NCHW上面的转换方法，在转换的时候为了优化卷积计算，它使用了维度融合这一方法、

4. 之后总结了在CNN上根据不同的维度特征选择了适应的数据布局从而提高了在GPU上面卷积层计算的性能。

---

存储器问题

这一章主要优化了另外的两层池化层和全连接层，并分析了不同数据布局在这两层上的特点。

---

实验结果

证明了数据布局对卷积层的性能有显著影响，并且开发了一种算法根据不同维度的CONV寻找合适的数据布局。

优化了数据布局转化算法，使选择最优数据布局+数据布局转换时间< 正常实现卷积的时间。